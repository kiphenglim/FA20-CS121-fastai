# -*- coding: utf-8 -*-
"""styleClassificationFastaiCSV.ipynb

Automatically generated by Colaboratory.

Original file is located at
  https://colab.research.google.com/drive/1XR7_7xGULam4mq-BwlT_MzmaWieLbC-s

# CS121  and CS152 - Assignment 2A

In this activity you'll download two classes of images, train a
classifier to distinguish them, and analyze the results.

##  Upload your images

Use Google images to download two classes of images into separate
folders on your computer. Zip each folder.

In the file view of your paperspace machine, navigate to the data
directory. Create a new folder called 'AB' where A is the name of your
first class and B is the name of your second class.

Run the following code to do some setup. Replace A and B with your
category names.

"""

from fastai.vision import *
import pathlib
import PIL
import pandas as pd
import numpy


## Read the cleaned CSVs and create a df
root = "wikiart/"
train = pd.read_csv(root+"wikiart_csv/style_train_clean.csv", header=None)
valid = pd.read_csv(root+"wikiart_csv/style_valid_clean.csv", header=None)
df = pd.concat([train, valid])
df.head()

style_dict = {0: "Abstract_Expressionism", 1: "Action_painting", 2: "Analytical_Cubism",
              3: "Art_Nouveau", 4: "Baroque", 5: "Color_Field_Painting",
              6: "Contemporary_Realism", 7: "Cubism", 8: "Early_Renaissance",
              9: "Expressionism", 10: "Fauvism", 11: "High_Renaissance",
              12: "Impressionism", 13: "Mannerism_Late_Renaissance",
              14: "Minimalism", 15: "Naive_Art_Primitivism", 16: "New_Realism",
              17: "Northern_Renaissance", 18: "Pointillism", 19: "Pop_Art",
              20: "Post_Impressionism", 21: "Realism", 22: "Rococo",
              23: "Romanticism", 24: "Symbolism", 25: "Synthetic_Cubism",
              26: "Ukiyo_e" }


## Sample max 200 photos/category
style_list = []
num_sample = 200
df.columns = ["path", "label"]

for key in style_dict:
  temp = df[df.label == style_dict[key]]
  print (str(style_dict[key]) + " " + str(len(temp.index)))
  if (len(temp.index) >= num_sample):
    temp = temp.sample(n = num_sample, random_state=1)
  style_list.append(temp)

style_df = pd.concat(style_list)
style_df.head()


## Create an ImageDataBunch from the dataframe
np.random.seed(42)

styles_path = root+"wikiart"
data = ImageDataBunch.from_df(df=style_df, path=styles_path,
                              valid_pct=0.2,
                              ds_tfms=get_transforms(),
                              size=180, num_workers=4).normalize(imagenet_stats)


## Verify the number of images
data.classes, data.c, len(data.train_ds), len(data.valid_ds)


## Create a CNN learner and train
learn = create_cnn(data, models.resnet34, metrics=error_rate)
learn.fit_one_cycle(20)
learn.save('stage-1')


## Load the CNN learner and figure out top losses
learn.load('stage-1');
interp = ClassificationInterpretation.from_learner(learn)
interp.plot_top_losses(9, figsize=(15,11))
interp.most_confused(min_val=2)
interp.plot_confusion_matrix()


## Export the learner
learn.export('allStylesBasic.pkl')


# Find a better learning rate
learn.lr_find()
learn.recorder.plot()


# Now with better learning rate
learn.unfreeze()
learn.fit_one_cycle(4, max_lr=slice(1e-4, 1e-2))


# Retrain with Many epochs
learn.fit_one_cycle(50, max_lr=slice(1e-4, 1e-2))
