# -*- coding: utf-8 -*-
"""styleClassificationFastaiCSV.ipynb

Automatically generated by Colaboratory.

Original file is located at
  https://colab.research.google.com/drive/1XR7_7xGULam4mq-BwlT_MzmaWieLbC-s

# CS121  and CS152 - Assignment 2A

In this activity you'll download two classes of images, train a
classifier to distinguish them, and analyze the results.

##  Upload your images

Use Google images to download two classes of images into separate
folders on your computer. Zip each folder.

In the file view of your paperspace machine, navigate to the data
directory. Create a new folder called 'AB' where A is the name of your
first class and B is the name of your second class.

Run the following code to do some setup. Replace A and B with your
category names.

"""

from fastai.vision import *
import pathlib
import PIL
import pandas as pd

"""Now unzip the files using the following code."""

from google.colab import drive
drive.mount('/content/drive')

"""At this point you should have a directory data/AB/A that contains
your A images and a directory data/AB/B that contains your B
images. For some reason, some people found that an intermediate
directory is created. For example, the A images were in data/ABC/A/A.
If this happened to you uncomment and run the following code, replace
A by your category name and then repeat for B."""

#root = "/content/drive/My Drive/CS Classes/CS 121/CS121F20_ Team_1_Art/Photos/"
#root = "/content/drive/My Drive/HMC/2020-2021/FA20-CS121/CS121F20_ Team_1_Art/Photos/"
root = "wikiart/"
train = pd.read_csv(root+"wikiart_csv/style_train_clean.csv", header=None)
valid = pd.read_csv(root+"wikiart_csv/style_valid_clean.csv", header=None)
df = pd.concat([train, valid])
df.head()

style_dict = {0: "Abstract_Expressionism", 1: "Action_painting", 2: "Analytical_Cubism",
              3: "Art_Nouveau", 4: "Baroque", 5: "Color_Field_Painting",
              6: "Contemporary_Realism", 7: "Cubism", 8: "Early_Renaissance",
              9: "Expressionism", 10: "Fauvism", 11: "High_Renaissance",
              12: "Impressionism", 13: "Mannerism_Late_Renaissance",
              14: "Minimalism", 15: "Naive_Art_Primitivism", 16: "New_Realism",
              17: "Northern_Renaissance", 18: "Pointillism", 19: "Pop_Art",
              20: "Post_Impressionism", 21: "Realism", 22: "Rococo",
              23: "Romanticism", 24: "Symbolism", 25: "Synthetic_Cubism",
              26: "Ukiyo_e" }

style_list = []
num_sample = 200
df.columns = ["path", "label"]
for key in style_dict:
  temp = df[df.label == style_dict[key]]
  print (str(style_dict[key]) + " " + str(len(temp.index)))
  if (len(temp.index) >= num_sample):
    temp = temp.sample(n = num_sample, random_state=1)
  style_list.append(temp)

style_df = pd.concat(style_list)
style_df.head()

"""## 5. View data"""

import numpy
np.random.seed(42)

styles_path = root+"Style/wikiart"
data = ImageDataBunch.from_df(df=style_df, path=styles_path,
                              valid_pct=0.2,
                              ds_tfms=get_transforms(),
                              size=180, num_workers=4).normalize(imagenet_stats)

"""Good! Let's take a look at some of our pictures then."""

data.classes, data.c, len(data.train_ds), len(data.valid_ds)

"""## 6.Train model

In this section you'll replicate the approach in lesson 2 to train
your model. Note the create_cnn has now been deprecated :( but it is
fine to use so ignore the warning.  """

learn = create_cnn(data, models.resnet34, metrics=error_rate)
learn.fit_one_cycle(20)
learn.save('stage-1')

"""## 7.Interpretation

In this section you'll replicate the approach in lesson 2 to interpret
your data.  """

learn.load('stage-1');
interp = ClassificationInterpretation.from_learner(learn)
interp.plot_top_losses(9, figsize=(15,11))
interp.most_confused(min_val=2)
interp.plot_confusion_matrix()

learn.export('allStylesBasic.pkl')

"""# 8. Improvements to the Model"""

from fastai.widgets import *
ds, idxs = DatasetFormatter().from_toplosses(learn, n_imgs=100)
ImageCleaner(ds, idxs, '/notebooks/course-v3/nbs/dl1/data')
df = pd.read_csv('data/cleaned.csv') 
data = ImageDataBunch.from_df(path=Path('data'), df=df,
                              ds_tfms=get_transforms(), size=224, bs=32)

data.classes, data.c, len(data.train_ds), len(data.valid_ds)

# Retrain on cleaned photos :)
learn.fit_one_cycle(4)
learn.save('stage-2')
learn.load('stage-2')
interp = ClassificationInterpretation.from_learner(learn)
interp.plot_top_losses(9, figsize=(15,11))
interp.most_confused(min_val=2)
interp.plot_confusion_matrix()

# Find a better learning rate
learn.lr_find()
learn.recorder.plot()

# Now with better learning rate
learn.unfreeze()
learn.fit_one_cycle(4, max_lr=slice(1e-4, 1e-2))

# Retrain with Many epochs
learn.fit_one_cycle(50, max_lr=slice(1e-4, 1e-2))

